# attention-branch-network

Attention Branch Networkï¼ˆABNï¼‰ã®å®Ÿè£…ã§ã™ã€‚`torchvision.datasets.Imagenette`ï¼ˆ10ã‚¯ãƒ©ã‚¹ï¼‰ã‚’ç”¨ã„ãŸç”»åƒåˆ†é¡ã«é©ç”¨ã—ã€ãƒ¢ãƒ‡ãƒ«ãŒã©ã“ã‚’è¦‹ã¦äºˆæ¸¬ã—ãŸã‹ã‚’å¯è¦–åŒ–ã§ãã¾ã™ã€‚

![Attention Maps](outputs/abn_attentions.png?v=1)

## æ¦‚è¦

ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯ ABN ã‚’ ResNet ç³»ãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³ä¸Šã«å®Ÿè£…ã—ã€Imagenette ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã®å­¦ç¿’ãƒ»è©•ä¾¡ãƒ»å¯è¦–åŒ–ã‚’è¡Œã„ã¾ã™ã€‚å­¦ç¿’ã«ã¯ Hugging Face `Trainer` ã‚’ç”¨ã„ã€å­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚„ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜ã‚’ç°¡æ½”ã«æ‰±ãˆã‚‹ã‚ˆã†ã«ã—ã¦ã„ã¾ã™ã€‚

## è¨“ç·´çµæœ

ResNet152 + ABN ã§ã® Imagenette 10ã‚¯ãƒ©ã‚¹åˆ†é¡ã®çµæœ:

- **Top-1 Accuracy**: 90.47%
- **Top-5 Accuracy**: 99.21%
- **Validation Loss**: 0.6205
- **Training Epochs**: 90 epochs

## å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«

ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§å­¦ç¿’ã—ãŸãƒ¢ãƒ‡ãƒ«ãŒHugging Face Hubã§å…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ï¼š

**ğŸ”— [yukiharada1228/abn-resnet152-imagenette](https://huggingface.co/yukiharada1228/abn-resnet152-imagenette)**

### ãƒ¢ãƒ‡ãƒ«ä»•æ§˜
- **ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£**: ResNet152 + Attention Branch Network
- **ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ**: Imagenette (10ã‚¯ãƒ©ã‚¹)
- **æ€§èƒ½**: Top-1 Accuracy 90.47%, Top-5 Accuracy 99.21%
- **ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚º**: 73.3M parameters
- **ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ**: Safetensors

### ä½¿ç”¨æ–¹æ³•

```python
from transformers import AutoModelForImageClassification
import torchvision.transforms as T
import torch

# ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿
model = AutoModelForImageClassification.from_pretrained(
    "yukiharada1228/abn-resnet152-imagenette",
    trust_remote_code=True,
)
model.eval()

# å‰å‡¦ç†
transform = T.Compose([
    T.Resize(256),
    T.CenterCrop(224),
    T.ToTensor(),
    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

# æ¨è«–
with torch.no_grad():
    outputs = model(pixel_values=pixel_values)
    logits = outputs.logits
    attention_map = model.model.attention_map  # (B,1,H,W)
```

### å¯è¦–åŒ–

å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ãŸå¯è¦–åŒ–ï¼š

```bash
uv run visualize.py --ckpt yukiharada1228/abn-resnet152-imagenette --out-dir outputs --prefix abn
```

## ä¸»ãªæ©Ÿèƒ½

- **Imagenette 10ã‚¯ãƒ©ã‚¹åˆ†é¡**: å…¬å¼ã® `train/val` åˆ†å‰²ã‚’ãã®ã¾ã¾åˆ©ç”¨
- **æ³¨æ„æ©Ÿæ§‹ã®å¯è¦–åŒ–**: åŸç”»åƒã¨ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—é‡ç•³ã‚’æ¨ªä¸¦ã³ãƒšã‚¢ã§ã‚°ãƒªãƒƒãƒ‰ä¿å­˜ï¼ˆã‚¯ãƒ©ã‚¹æ•°ã«åˆã‚ã›ã¦æ­£æ–¹ã«è¿‘ã„ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã€‚ä¾‹: 10ã‚¯ãƒ©ã‚¹ â†’ 2Ã—5 ãƒšã‚¢ï¼‰
- **è¤‡æ•°ã® ResNet å¯¾å¿œ**: ResNet18/34/50/101/152
- **Trainer é€£æº**: æœ€è‰¯ãƒ¢ãƒ‡ãƒ«ã®è‡ªå‹•ä¿å­˜ãƒ»èª­ã¿è¾¼ã¿ã«å¯¾å¿œ
- **ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆäº’æ›**: `model.safetensors` ã¨ `checkpoint-XXXX` ã®ã©ã¡ã‚‰ã‹ã‚‰ã§ã‚‚å¯è¦–åŒ–å¯èƒ½

## ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ 

```
attention-branch-network/
â”œâ”€â”€ models/                 # ABN ãƒ¢ãƒ‡ãƒ«å®Ÿè£…ï¼ˆHFäº’æ›ï¼‰
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ configuration_abn.py
â”‚   â”œâ”€â”€ modeling_abn.py
â”‚   â””â”€â”€ resnet_abn_backbone.py
â”œâ”€â”€ data/                  # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆåˆå›å®Ÿè¡Œæ™‚ã«è‡ªå‹•ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼‰
â”‚   â””â”€â”€ Imagenette/
â”œâ”€â”€ checkpoint/            # Trainer å‡ºåŠ›ï¼ˆæœ€è‰¯ãƒ¢ãƒ‡ãƒ«ã‚„ epoch ã”ã¨ã® ckptï¼‰
â”‚   â””â”€â”€ runs/              # TensorBoard äº’æ›ãƒ­ã‚°
â”œâ”€â”€ outputs/               # å¯è¦–åŒ–çµæœï¼ˆã¾ã¨ã‚ç”»åƒï¼‰
â”‚   â””â”€â”€ abn_attentions.png
â”œâ”€â”€ train.py               # å­¦ç¿’ãƒ»è©•ä¾¡ï¼ˆHF Trainerï¼‰
â”œâ”€â”€ visualize.py           # æ³¨æ„ãƒãƒƒãƒ—å¯è¦–åŒ–
â”œâ”€â”€ main.py                # ã‚¨ãƒ³ãƒˆãƒªï¼ˆã‚µãƒ³ãƒ—ãƒ«ï¼‰
â”œâ”€â”€ pyproject.toml         # ä¾å­˜é–¢ä¿‚ï¼ˆuv å¯¾å¿œï¼‰
â””â”€â”€ uv.lock
```

## å‹•ä½œç’°å¢ƒ

- Python 3.12 ä»¥ä¸Š
- CUDA ç’°å¢ƒï¼ˆGPU æ¨å¥¨ã€‚`--cpu` ã§CPUå®Ÿè¡Œå¯ï¼‰

## ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

```bash
# uv ã‚’ä½¿ç”¨ï¼ˆæ¨å¥¨ï¼‰
uv sync
```

## ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆImagenetteï¼‰

`train.py`/`visualize.py` ã¯åˆå›å®Ÿè¡Œæ™‚ã« Imagenette ã‚’è‡ªå‹•ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚

- æ—¢å®šã®ä¿å­˜å…ˆ: `./data/Imagenette`
- ã‚µã‚¤ã‚ºæŒ‡å®š: `--imagenette-size {full|320px|160px}`ï¼ˆæ—¢å®š: `full`ï¼‰

## ä½¿ã„æ–¹

### å­¦ç¿’

```bash
uv run train.py
```

- æœ€è‰¯ãƒ¢ãƒ‡ãƒ«ã¯ `--checkpoint` ã§æŒ‡å®šã—ãŸãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ä¿å­˜ã•ã‚Œã¾ã™ï¼ˆä¾‹: `checkpoint/model.safetensors`ï¼‰ã€‚
- å­¦ç¿’é€”ä¸­ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã¯ `checkpoint-XXXX/` å½¢å¼ã§ä¿å­˜ã•ã‚Œã¾ã™ã€‚
- ãƒ­ã‚°: TensorBoard äº’æ›ã®ã‚¤ãƒ™ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ `checkpoint/runs/` ã«å‡ºåŠ›ã—ã¾ã™ã€‚

#### è©•ä¾¡ã®ã¿

```bash
uv run train.py --evaluate --checkpoint checkpoint --gpu-id 0
```

### å¯è¦–åŒ–ï¼ˆæ³¨æ„ãƒãƒƒãƒ—ï¼‰

æœ€è‰¯ãƒ¢ãƒ‡ãƒ«ï¼ˆ`checkpoint/model.safetensors`ï¼‰ã¾ãŸã¯ä»»æ„ã® `checkpoint-XXXX/` ã‚’æŒ‡å®šã§ãã¾ã™ã€‚

```bash
# æœ€è‰¯ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰å¯è¦–åŒ–ï¼ˆæ—¢å®šãƒ‘ã‚¹ï¼‰
uv run visualize.py --ckpt checkpoint/model.safetensors --out-dir outputs --prefix abn

# ã‚ã‚‹ã‚¨ãƒãƒƒã‚¯ã® ckpt ã‚’æŒ‡å®š
uv run visualize.py --ckpt checkpoint/checkpoint-1924 --out-dir outputs --prefix abn
```

ä¸»ãªã‚ªãƒ—ã‚·ãƒ§ãƒ³:

- å­¦ç¿’ï¼ˆtrain.pyï¼‰
  - `--arch {resnet18,resnet34,resnet50,resnet101,resnet152}`ï¼ˆæ—¢å®š: `resnet152`ï¼‰
  - `--imagenette-root`ï¼ˆæ—¢å®š: `./data/Imagenette`ï¼‰ / `--imagenette-size {full|320px|160px}`ï¼ˆæ—¢å®š: `full`ï¼‰
  - `-j/--workers`ï¼ˆæ—¢å®š: 4ï¼‰
  - `--train-batch`ï¼ˆæ—¢å®š: 64ï¼‰/`--test-batch`ï¼ˆæ—¢å®š: 100ï¼‰
  - `--epochs`ï¼ˆæ—¢å®š: 90ï¼‰/`--lr`ï¼ˆæ—¢å®š: 0.1ï¼‰/`--momentum`ï¼ˆæ—¢å®š: 0.9ï¼‰/`--wd`ï¼ˆæ—¢å®š: 1e-4ï¼‰
  - `--schedule`ï¼ˆæ—¢å®š: `31 61`ï¼‰/`--gamma`ï¼ˆæ—¢å®š: 0.1ï¼‰
  - `--checkpoint`ï¼ˆå‡ºåŠ›å…ˆã€æ—¢å®š: `checkpoint`ï¼‰/`--resume`ï¼ˆå­¦ç¿’å†é–‹ï¼‰
  - `--evaluate`ï¼ˆè©•ä¾¡ã®ã¿ï¼‰/`--gpu-id`ï¼ˆCUDA ãƒ‡ãƒã‚¤ã‚¹æŒ‡å®šï¼‰/`--push-to-hub`ï¼ˆä»»æ„ï¼‰

- å¯è¦–åŒ–ï¼ˆvisualize.pyï¼‰
  - `--ckpt`ï¼ˆæ—¢å®š: `checkpoint/model.safetensors`ã€‚`checkpoint-XXXX/` ã‚‚å¯ï¼‰
  - `--out-dir`ï¼ˆæ—¢å®š: `outputs`ï¼‰/`--prefix`ï¼ˆæ—¢å®š: `abn`ï¼‰/`--dpi`ï¼ˆæ—¢å®š: 200ï¼‰
  - `--attention-alpha`ï¼ˆ0.0â€“1.0ã€æ—¢å®š: 1.0ã€‚1.0ã§å˜ç´”åŠ ç®—ï¼‰/`--no-display`
  - `--arch` / `--imagenette-root` / `--imagenette-size` / `-j/--workers` / `--gpu-id` ã¾ãŸã¯ `--cpu`

## å¯è¦–åŒ–çµæœãƒ»ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 

- `outputs/{prefix}_attentions.png` ã«ã€åŸç”»åƒã¨é‡ç•³ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã®ãƒšã‚¢ã‚’ã‚¿ã‚¤ãƒ«é…ç½®ã§ä¿å­˜ã—ã¾ã™ï¼ˆæ—¢å®š: `abn_attentions.png`ï¼‰ã€‚

å®Ÿè£…ã®è¦ç‚¹ï¼ˆABN è«–æ–‡å®Ÿè£…ã«æº–æ‹ ã—ã¤ã¤ç°¡æ½”ãƒ»é«˜é€ŸåŒ–ï¼‰:

1. ç”»åƒå¾©å…ƒ: ImageNet çµ±è¨ˆã§ã®æ­£è¦åŒ–ã‚’åè»¢ã—ã€RGBâ†’BGR ã«å¤‰æ›
2. ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³: `attention[0]` ã‚’ å…¥åŠ›è§£åƒåº¦ã¸ `cv2.resize`
3. ã‚«ãƒ©ãƒ¼ãƒãƒƒãƒ—: `cv2.COLORMAP_JET` ã‚’é©ç”¨
4. åˆæˆ: `cv2.add(original_bgr, jet_map)`ã€‚`--attention-alpha` ã§å¼·åº¦èª¿æ•´ï¼ˆ1.0 ã§å˜ç´”åŠ ç®—ï¼‰
5. ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ: å„ã‚¯ãƒ©ã‚¹ã‹ã‚‰1æšãšã¤æŠ½å‡ºã—ã€å·¦ã«åŸç”»åƒãƒ»å³ã«é‡ç•³ç”»åƒã®ãƒšã‚¢ã‚’ã‚¿ã‚¤ãƒ«é…ç½®
6. è¡¨ç¤º: æ—¢å®šã§è¡¨ç¤ºã€`--no-display` ã§ä¿å­˜ã®ã¿

## å¯¾å¿œã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

- ResNet18
- ResNet34
- ResNet50
- ResNet101
- ResNet152

## ä¾å­˜é–¢ä¿‚

- PyTorch / torchvision
- Transformers / Accelerate
- NumPy
- Matplotlibï¼ˆå¯è¦–åŒ–ï¼‰
- OpenCVï¼ˆç”»åƒå‡¦ç†ï¼‰
- TensorBoardXï¼ˆãƒ­ã‚°å‡ºåŠ›ï¼‰

`pyproject.toml` ã«å®šç¾©æ¸ˆã¿ã§ã™ã€‚`uv sync` ã§ç’°å¢ƒæ§‹ç¯‰ã§ãã¾ã™ã€‚

## ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

ã“ã®ãƒªãƒã‚¸ãƒˆãƒªã® `LICENSE` ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚

## Acknowledgements

This project includes code from:
"Attention Branch Network: Learning of Attention Mechanism for Visual Explanation"  
by Hiroshi Fukui, Tsubasa Hirakawa, Takayoshi Yamashita, and Hironobu Fujiyoshi,  
licensed under the MIT License.  
Original repository: [https://github.com/machine-perception-robotics-group/attention_branch_network](https://github.com/machine-perception-robotics-group/attention_branch_network)
